{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train, test, target_column='is_fraud'):\n",
    "    train = train.dropna(subset=[target_column])\n",
    "    test = test.dropna(subset=[target_column])\n",
    "    \n",
    "    x_train = train.drop([target_column], axis=1)\n",
    "    y_train = train[target_column]\n",
    "    x_test = test.drop([target_column], axis=1)\n",
    "    y_test = test[target_column]\n",
    "    \n",
    "    x_train = x_train.select_dtypes(include=['int64','float64'])\n",
    "    x_test = x_test.select_dtypes(include=['int64','float64'])\n",
    "    \n",
    "    n = [col for col in x_train.columns if train[col].isnull().sum() > 0]\n",
    "    x_train.drop(n, axis=1, inplace=True)\n",
    "    x_test.drop(n, axis=1, inplace=True)\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    x_train = scale.fit_transform(x_train)\n",
    "    x_test = scale.transform(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def feature_selection(x_train, y_train, k=10):\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    x_train_selected = selector.fit_transform(x_train, y_train)\n",
    "    return x_train_selected, selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "Confusion Matrix:\n",
      " [[553222    352]\n",
      " [  2145      0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.00      0.00      0.00      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.50      0.50      0.50    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n",
      "Accuracy Score: 0.9955067219224104\n",
      "\n",
      "Random Forest Results:\n",
      "Confusion Matrix:\n",
      " [[553246    328]\n",
      " [  1959    186]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    553574\n",
      "           1       0.36      0.09      0.14      2145\n",
      "\n",
      "    accuracy                           1.00    555719\n",
      "   macro avg       0.68      0.54      0.57    555719\n",
      "weighted avg       0.99      1.00      0.99    555719\n",
      "\n",
      "Accuracy Score: 0.9958846107475181\n",
      "\n",
      "Decision Tree Results:\n",
      "Confusion Matrix:\n",
      " [[508699  44875]\n",
      " [  1289    856]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96    553574\n",
      "           1       0.02      0.40      0.04      2145\n",
      "\n",
      "    accuracy                           0.92    555719\n",
      "   macro avg       0.51      0.66      0.50    555719\n",
      "weighted avg       0.99      0.92      0.95    555719\n",
      "\n",
      "Accuracy Score: 0.9169292394177633\n",
      "\n",
      "Summary of Results:\n",
      "Logistic Regression - Accuracy: 0.9955067219224104\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.9961376891316913, 'recall': 0.9993641319859675, 'f1-score': 0.9977483022090445, 'support': 553574.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2145.0}, 'accuracy': 0.9955067219224104, 'macro avg': {'precision': 0.49806884456584566, 'recall': 0.49968206599298376, 'f1-score': 0.49887415110452227, 'support': 555719.0}, 'weighted avg': {'precision': 0.9922927327001361, 'recall': 0.9955067219224104, 'f1-score': 0.9938971290293648, 'support': 555719.0}}\n",
      "Random Forest - Accuracy: 0.9958846107475181\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.9964715735629182, 'recall': 0.9994074866232879, 'f1-score': 0.9979373707474618, 'support': 553574.0}, '1': {'precision': 0.36186770428015563, 'recall': 0.08671328671328671, 'f1-score': 0.13990221887927792, 'support': 2145.0}, 'accuracy': 0.9958846107475181, 'macro avg': {'precision': 0.6791696389215369, 'recall': 0.5430603866682873, 'f1-score': 0.5689197948133699, 'support': 555719.0}, 'weighted avg': {'precision': 0.9940220886620752, 'recall': 0.9958846107475181, 'f1-score': 0.9946254713868905, 'support': 555719.0}}\n",
      "Decision Tree - Accuracy: 0.9169292394177633\n",
      "Classification Report:\n",
      "{'0': {'precision': 0.9974724895487737, 'recall': 0.918935860426971, 'f1-score': 0.9565949140717701, 'support': 553574.0}, '1': {'precision': 0.018718156174148827, 'recall': 0.3990675990675991, 'f1-score': 0.035759044197510234, 'support': 2145.0}, 'accuracy': 0.9169292394177633, 'macro avg': {'precision': 0.5080953228614612, 'recall': 0.659001729747285, 'f1-score': 0.49617697913464015, 'support': 555719.0}, 'weighted avg': {'precision': 0.9936946305137423, 'recall': 0.9169292394177633, 'f1-score': 0.9530406124537216, 'support': 555719.0}}\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, model_name=\"Model\"):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred), classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "def main():\n",
    "    train, test = load_data('fraudTrain.csv', 'fraudTest.csv')\n",
    "    x_train, y_train, x_test, y_test = preprocess_data(train, test)\n",
    "    x_train, selector = feature_selection(x_train, y_train, k=10)\n",
    "    x_test = selector.transform(x_test)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        acc, report = train_and_evaluate_model(model, x_train, y_train, x_test, y_test, model_name)\n",
    "        results[model_name] = {\"accuracy\": acc, \"report\": report}\n",
    "\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"{model_name} - Accuracy: {result['accuracy']}\")\n",
    "        print(f\"Classification Report:\\n{result['report']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
